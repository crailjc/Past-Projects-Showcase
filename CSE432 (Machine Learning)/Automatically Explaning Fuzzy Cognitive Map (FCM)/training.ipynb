{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 168 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- All prompts end with suffix ` <E>`\n",
      "  WARNING: Some of your prompts contain the suffix ` <E>` more than once. We strongly suggest that you review your prompts and add a unique suffix\n",
      "- All prompts start with prefix `Initial: <S> `. Fine-tuning doesn't require the instruction specifying the task, or a few-shot example scenario. Most of the time you should only add the input data into the prompt, and the desired output into the completion\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove prefix `Initial: <S> ` from all prompts [Y/n]: ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f \"original.jsonl\"\n",
    "# this won't work if I am running in visual studio code... so this file is actually run in google colab which allows user inputs.\n",
    "# Visual studio code somehow does not allow user inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If dataset is small, openai doesn't auto separate dataset\n",
    "\n",
    "We have separated 80 annotated sentences into 80:10:10 (train, validation, test) proportions.\n",
    "\n",
    "Only train will be augmented everytime, while validation and test will remain as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -m ada --n_epochs 5 -t \"permuted_prepared_train.jsonl\" -v \"permuted_prepared_valid.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_id = \"curie:ft-personal-2022-12-01-16-02-45\" # total\n",
    "TEST_FILENAME = \"annotated/test.jsonl\"\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "outfile = open(\"evaluate/original.json\", 'w')\n",
    "results = []\n",
    "\n",
    "with open(TEST_FILENAME) as f:\n",
    "  while (line := f.readline().rstrip()):\n",
    "    json_data = json.loads(line)\n",
    "    prompt, expected = json_data['prompt'], json_data['completion']\n",
    "\n",
    "    s = openai.Completion.create(\n",
    "      model=finetune_id,\n",
    "      prompt=prompt,\n",
    "      max_tokens=256,\n",
    "      temperature=1,\n",
    "    )\n",
    "    s = s['choices'][0]['text'].split('<end>')[0] + '<end>'  # to stay consistent with expected output\n",
    "    generated =  s.split('<End')[0]\n",
    "    results.append({\"generated\":generated,\"expected\":expected.split('<End')[0]})\n",
    "\n",
    "outfile.write(json.dumps(results))\n",
    "outfile.close()\n",
    "print(f'All results generated into file: {outfile.name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
